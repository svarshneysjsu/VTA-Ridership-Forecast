{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    ">>> df[\"Latitude\"].min()\n",
    "36.974922\n",
    ">>> df[\"Latitude\"].max()\n",
    "37.558388\n",
    ">>> df[\"Longitude\"].min()\n",
    "-122.17364\n",
    ">>> df[\"Longitude\"].max()\n",
    "-121.54903\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_DATA_FOLDER = \"raw_data\"\n",
    "STAGING_DATA_FOLDER = \"staging_data\"\n",
    "ELEMENTS = [\"TMAX\", \"TMIN\", \"PRCP\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations = (\n",
    "    pl.scan_csv(os.path.join(RAW_DATA_FOLDER, \"stations.csv\"))\n",
    "    .select([\"id\", \"latitude\", \"longitude\"])\n",
    "    .with_columns(\n",
    "        pl.col(\"latitude\").cast(pl.Float32), pl.col(\"longitude\").cast(pl.Float32)\n",
    "    )\n",
    "    .filter((pl.col(\"latitude\").ge(36.97)) & (pl.col(\"latitude\").le(37.56)))\n",
    "    .filter((pl.col(\"longitude\").ge(-122.18)) & (pl.col(\"longitude\").le(-121.54)))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "climate = (\n",
    "    pl.scan_csv(os.path.join(RAW_DATA_FOLDER, \"2014.csv\"))\n",
    "    .select([pl.col(\"ID\"), pl.col(\"DATE\"), pl.col(\"ELEMENT\"), pl.col(\"DATA_VALUE\")])\n",
    "    .with_columns(pl.col(\"DATE\").cast(pl.Utf8).str.strptime(pl.Date, \"%Y%m%d\"))\n",
    "    .with_columns((pl.col(\"DATA_VALUE\") / 10).cast(pl.Float32))\n",
    "    .filter(pl.col(\"ELEMENT\").is_in(ELEMENTS))\n",
    "    .filter(pl.col(\"ID\").is_in(stations.select(\"id\").collect()))\n",
    "    .unique([\"ID\", \"DATE\", \"ELEMENT\"])\n",
    "    .group_by([\"ID\", \"DATE\"])\n",
    "    .agg(\n",
    "        pl.col(\"DATA_VALUE\")\n",
    "        .filter(pl.col(\"ELEMENT\").eq(element))\n",
    "        .alias(element)\n",
    "        .mean()\n",
    "        for element in ELEMENTS\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lf = (\n",
    "    pl.scan_csv(os.path.join(RAW_DATA_FOLDER, \"2015.csv\"))\n",
    "    .select([pl.col(\"ID\"), pl.col(\"DATE\"), pl.col(\"ELEMENT\"), pl.col(\"DATA_VALUE\")])\n",
    "    .with_columns(pl.col(\"DATE\").cast(pl.Utf8).str.strptime(pl.Date, \"%Y%m%d\"))\n",
    "    .with_columns((pl.col(\"DATA_VALUE\") / 10).cast(pl.Float32))\n",
    "    .filter(pl.col(\"ELEMENT\").is_in(ELEMENTS))\n",
    "    .filter(pl.col(\"ID\").is_in(stations.select(\"id\").collect()))\n",
    "    .unique([\"ID\", \"DATE\", \"ELEMENT\"])\n",
    "    .group_by([\"ID\", \"DATE\"])\n",
    "    .agg(\n",
    "        pl.col(\"DATA_VALUE\")\n",
    "        .filter(pl.col(\"ELEMENT\").eq(element))\n",
    "        .alias(element)\n",
    "        .mean()\n",
    "        for element in ELEMENTS\n",
    "    )\n",
    ")\n",
    "climate = pl.concat([climate, lf], how=\"vertical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lf = (\n",
    "    pl.scan_csv(os.path.join(RAW_DATA_FOLDER, \"2016.csv\"))\n",
    "    .select([pl.col(\"ID\"), pl.col(\"DATE\"), pl.col(\"ELEMENT\"), pl.col(\"DATA_VALUE\")])\n",
    "    .with_columns(pl.col(\"DATE\").cast(pl.Utf8).str.strptime(pl.Date, \"%Y%m%d\"))\n",
    "    .with_columns((pl.col(\"DATA_VALUE\") / 10).cast(pl.Float32))\n",
    "    .filter(pl.col(\"ELEMENT\").is_in(ELEMENTS))\n",
    "    .filter(pl.col(\"ID\").is_in(stations.select(\"id\").collect()))\n",
    "    .unique([\"ID\", \"DATE\", \"ELEMENT\"])\n",
    "    .group_by([\"ID\", \"DATE\"])\n",
    "    .agg(\n",
    "        pl.col(\"DATA_VALUE\")\n",
    "        .filter(pl.col(\"ELEMENT\").eq(element))\n",
    "        .alias(element)\n",
    "        .mean()\n",
    "        for element in ELEMENTS\n",
    "    )\n",
    ")\n",
    "climate = pl.concat([climate, lf], how=\"vertical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lf = (\n",
    "    pl.scan_csv(os.path.join(RAW_DATA_FOLDER, \"2017.csv\"))\n",
    "    .select([pl.col(\"ID\"), pl.col(\"DATE\"), pl.col(\"ELEMENT\"), pl.col(\"DATA_VALUE\")])\n",
    "    .with_columns(pl.col(\"DATE\").cast(pl.Utf8).str.strptime(pl.Date, \"%Y%m%d\"))\n",
    "    .with_columns((pl.col(\"DATA_VALUE\") / 10).cast(pl.Float32))\n",
    "    .filter(pl.col(\"ELEMENT\").is_in(ELEMENTS))\n",
    "    .filter(pl.col(\"ID\").is_in(stations.select(\"id\").collect()))\n",
    "    .unique([\"ID\", \"DATE\", \"ELEMENT\"])\n",
    "    .group_by([\"ID\", \"DATE\"])\n",
    "    .agg(\n",
    "        pl.col(\"DATA_VALUE\")\n",
    "        .filter(pl.col(\"ELEMENT\").eq(element))\n",
    "        .alias(element)\n",
    "        .mean()\n",
    "        for element in ELEMENTS\n",
    "    )\n",
    ")\n",
    "climate = pl.concat([climate, lf], how=\"vertical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "climate95 = (\n",
    "    climate.group_by(\"ID\")\n",
    "    .agg(\n",
    "        [\n",
    "            pl.col(\"DATE\").len(),\n",
    "            pl.col(\"TMAX\").null_count(),\n",
    "            pl.col(\"TMIN\").null_count(),\n",
    "            pl.col(\"PRCP\").null_count(),\n",
    "        ]\n",
    "    )\n",
    "    .filter((pl.col(\"PRCP\") / pl.col(\"DATE\")) < 0.05)\n",
    "    .filter((pl.col(\"TMAX\") / pl.col(\"DATE\")) < 0.05)\n",
    "    .select(\"ID\")\n",
    "    .collect()\n",
    ")\n",
    "climate = climate.filter(pl.col(\"ID\").is_in(climate95))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = (\n",
    "    pl.scan_csv(os.path.join(STAGING_DATA_FOLDER, \"dates.csv\"))\n",
    "    .with_columns(\n",
    "        pl.col(\"id\").cast(pl.Utf8).str.strptime(pl.Date, \"%Y%m%d\").alias(\"DATE\")\n",
    "    )\n",
    "    .select(pl.col(\"DATE\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_stations = climate.select(\"ID\").unique()\n",
    "unique_stations = unique_stations.join(dates, on=\"DATE\", how=\"cross\")\n",
    "climate = unique_stations.join(climate, on=[\"ID\", \"DATE\"], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_median(df, group):\n",
    "    # Calculate median per group\n",
    "    median_df = df.group_by([\"ID\", \"YEAR\", group]).agg(\n",
    "        pl.col(\"TMAX\").median().alias(\"median_TMAX\"),\n",
    "        pl.col(\"TMIN\").median().alias(\"median_TMIN\"),\n",
    "        pl.col(\"PRCP\").median().alias(\"median_PRCP\"),\n",
    "    )\n",
    "    # Join back to the original data to align the medians\n",
    "    df = df.join(median_df, on=[\"ID\", \"YEAR\", group])\n",
    "    # Impute the nulls with the corresponding median\n",
    "    df = df.with_columns(\n",
    "        pl.when(pl.col(\"TMAX\").is_null())\n",
    "        .then(pl.col(\"median_TMAX\"))\n",
    "        .otherwise(pl.col(\"TMAX\"))\n",
    "        .alias(\"TMAX\"),\n",
    "        pl.when(pl.col(\"TMIN\").is_null())\n",
    "        .then(pl.col(\"median_TMIN\"))\n",
    "        .otherwise(pl.col(\"TMIN\"))\n",
    "        .alias(\"TMIN\"),\n",
    "        pl.when(pl.col(\"PRCP\").is_null())\n",
    "        .then(pl.col(\"median_PRCP\"))\n",
    "        .otherwise(pl.col(\"PRCP\"))\n",
    "        .alias(\"PRCP\"),\n",
    "    )\n",
    "    # Drop the median column after imputation\n",
    "    df = df.drop([\"median_TMAX\", \"median_TMIN\", \"median_PRCP\"])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "climate = climate.with_columns(\n",
    "    pl.col(\"DATE\").dt.year().alias(\"YEAR\"),\n",
    "    pl.col(\"DATE\").dt.week().alias(\"WEEK\"),\n",
    "    pl.col(\"DATE\").dt.month().alias(\"MONTH\"),\n",
    "    pl.col(\"DATE\").dt.quarter().alias(\"QUARTER\"),\n",
    ")\n",
    "# climate = climate.pipe(impute_median, \"WEEK\")\n",
    "climate = climate.pipe(impute_median, \"MONTH\")\n",
    "# climate = climate.pipe(impute_median, \"QUARTER\")\n",
    "climate = climate.drop([\"YEAR\", \"WEEK\", \"MONTH\", \"QUARTER\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "climate = climate.with_columns(\n",
    "    pl.col(\"TMAX\").fill_null(pl.col(\"TMAX\").median()),\n",
    "    pl.col(\"TMIN\").fill_null(pl.col(\"TMIN\").median()),\n",
    "    pl.col(\"PRCP\").fill_null(0.0),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "climate = climate.join(stations, how=\"left\", left_on=\"ID\", right_on=\"id\").select(\n",
    "    [\n",
    "        pl.col(\"DATE\").alias(\"Date\"),\n",
    "        pl.col(\"latitude\").alias(\"Latitude\"),\n",
    "        pl.col(\"longitude\").alias(\"Longitude\"),\n",
    "        pl.col(\"TMAX\").alias(\"Tmax\"),\n",
    "        pl.col(\"TMIN\").alias(\"Tmin\"),\n",
    "        pl.col(\"PRCP\").alias(\"Prcp\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "climate.collect(streaming=True).write_csv(\n",
    "    os.path.join(STAGING_DATA_FOLDER, \"climate.csv\")\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
